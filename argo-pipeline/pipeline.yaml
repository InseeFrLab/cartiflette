apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: cartiflette-pipeline-
  namespace: projet-cartiflette
spec:
  entrypoint: main
  serviceAccountName: workflow
  volumeClaimTemplates:
    - metadata:
        name: volume-workflow-tmp
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 10Gi


  templates:
    - name: main

  # --------------------------
  # DAG COMPONENTS
  # ---------------------------

      dag:
        tasks:

          # STEP 0 : MOUNT VOLUMES AND CHECK PERMISSIONS
          - name: init-and-test-volume
            template: init-and-test-volume

          # STEP 1 : RETRIEVE ALL (NEW) FILES FROM SOURCES AND UPLOAD TO MINIO
          - name: download-all-sources
            template: download-all-sources
            dependencies: [ init-and-test-volume ]

          # STEP 2 : CHECK WICH VINTAGE SHOULD BE RE-PROCESSED FROM (NEW) RAW SOURCES
          - name: select-downstream-vintage-to-process
            template: select-downstream-vintage-to-process
            dependencies: [ download-all-sources ]
            arguments:
              parameters:
              - name: download_results
                value: "{{tasks.download-all-sources.outputs.parameters.download_all_results}}"

          # STEP 3.1 : CREATE BASE GEODATASETS ON MINIO FROM RAW TERRITORIAL FILES
          # TODO : skip to one pod for each available year
          - name: make-geodatasets
            template: make-geodatasets
            dependencies: [ select-downstream-vintage-to-process ]
            arguments:
              parameters:
              - name: years
                value: "{{tasks.select-downstream-vintage-to-process.outputs.parameters.geodatasets_vintage_to_update}}"

          # STEP 3.2 : CREATE METADATA FILES ON MINIO FROM RAW INSEE FILES
          - name: make-metadata
            template: make-metadata
            dependencies: [ select-downstream-vintage-to-process ]
            arguments:
              parameters:
              - name: years
                value: "{{tasks.select-downstream-vintage-to-process.outputs.parameters.metadata_vintage_to_update}}"
          
          # STEP 4 : SELECT DOWNSTREAM DATASETS TO GENERATE
          - name: select-downstream-datasets-to-generate
            template: select-downstream-datasets-to-generate
            dependencies: [ make-geodatasets, make-metadata ]
            arguments:
              parameters:
              - name: years_geodatasets
                value: "{{tasks.make-geodatasets.outputs.parameters.updated_geodata}}"
              - name: years_metadata
                value: "{{tasks.make-metadata.outputs.parameters.updated_metadata}}"

          # STEP 5 : SPLIT DATASETS
          - name: generate
            template: split-dataset
            dependencies: [ select-downstream-datasets-to-generate ]
            arguments:
              parameters:
              - name: key
                value: "{{item.key}}"
              - name: config
                value: "{{item.config}}"
            withParam: "{{tasks.select-downstream-datasets-to-generate.outputs.parameters.configs}}"

  # --------------------------
  # TEMPLATES DEFINITION
  # ---------------------------

    - name: init-and-test-volume
      inputs:
        artifacts:
          - name: code
            path: /mnt/bin
            git:
              repo: https://github.com/inseefrlab/cartiflette
              revision: "feat/refacto_pipeline_first_steps"
      container:
        image: inseefrlab/cartiflette:latest
        command: [sh, -c]
        args: ["mkdir -p /mnt/bin/src ;
                mv /mnt/bin/argo-pipeline/src/* /mnt/bin/src ;
                echo $PATH_WRITING_S3"]
        volumeMounts:
          - name: volume-workflow-tmp
            mountPath: /mnt
        env: &env_parameters
          - name: PATH_WRITING_S3
            value: "test"
          - name: PYTHONPATH
            value: "${PYTHONPATH}:/mnt/bin"
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: sa-cartiflette
                key: accessKey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: sa-cartiflette
                key: secretKey
          - name: AWS_DEFAULT_REGION
            value: us-east-1
          - name: AWS_S3_ENDPOINT
            value: minio.lab.sspcloud.fr
          - name: MC_HOST_s3
            value: https://$AWS_ACCESS_KEY_ID:$AWS_SECRET_ACCESS_KEY@$AWS_S3_ENDPOINT
            
    - name: download-all-sources
      outputs:
        parameters:
        - name: download_all_results
          valueFrom:
            path: download_all_results.json
      container:
        image: inseefrlab/cartiflette:latest
        command: [sh, -c]
        args: ["
          python /mnt/bin/src/download_all_sources.py --path $PATH_WRITING_S3 --years 2024,2023;
          "]
        volumeMounts:
          - name: volume-workflow-tmp
            mountPath: /mnt
        env: *env_parameters

    - name: select-downstream-vintage-to-process
      inputs:
        parameters:
          - name: download_results
      outputs:
        parameters:
        - name: geodatasets_vintage_to_update
          valueFrom:
            path: geodatasets_years.json
        - name: metadata_vintage_to_update
          valueFrom:
            path: metadata_years.json
      container:
        image: inseefrlab/cartiflette:latest
        command: [sh, -c]
        volumeMounts:
          - name: volume-workflow-tmp
            mountPath: /mnt
        args: ["
          python /mnt/bin/src/select_downstream_vintage_to_process.py --download_results '{{inputs.parameters.download_results}}'
          "]
        env: *env_parameters

    - name: make-geodatasets
      inputs:
        parameters:
          - name: years
      outputs:
        parameters:
        - name: updated_geodata
          valueFrom:
            path: geodatasets_years.json
      container:
        image: inseefrlab/cartiflette:latest
        command: [sh, -c]
        volumeMounts:
          - name: volume-workflow-tmp
            mountPath: /mnt
        args: ["
                python /mnt/bin/src/make_geodata_datasets.py --path $PATH_WRITING_S3 --years '{{inputs.parameters.years}}';
                "]
        env: *env_parameters
        
    - name: make-metadata
      inputs:
        parameters:
          - name: years
      outputs:
        parameters:
        - name: updated_metadata
          valueFrom:
            path: metadata_years.json
      container:
        image: inseefrlab/cartiflette:latest
        command: [sh, -c]
        volumeMounts:
          - name: volume-workflow-tmp
            mountPath: /mnt
        args: ["
                python /mnt/bin/src/make_metadata_datasets.py --path $PATH_WRITING_S3 --years '{{inputs.parameters.years}}';
                "]
        env: *env_parameters
        
    
    - name: select-downstream-datasets-to-generate
      inputs:
        parameters:
          - name: years_geodatasets
          - name: years_metadata
      outputs:
        parameters:
        - name: configs
          valueFrom:
            path: configs_datasets_to_generate.json
      container:
        image: inseefrlab/cartiflette:latest
        command: [sh, -c]
        volumeMounts:
          - name: volume-workflow-tmp
            mountPath: /mnt
        env: *env_parameters
        args: ["
          python /mnt/bin/src/crossproduct.py --years-geodatasets '{{inputs.parameters.years_geodatasets}}' --years-metadata '{{inputs.parameters.years_metadata}}';
          "]

  # Step 2: creating template task for splitting ------------------
    - name: split-dataset
      inputs:
        parameters:
        - name: key
        - name: config
      container:
        image: inseefrlab/cartiflette:latest
        command: ["sh", "-c"]
        args: ["
          python /mnt/bin/src/split_merge_tiles.py \
          --path $PATH_WRITING_S3 \
          --key {{inputs.parameters.key}} \
          --config {{inputs.parameters.config}}"
        ]
        volumeMounts:
          - name: volume-workflow-tmp
            mountPath: /mnt
        env: *env_parameters

